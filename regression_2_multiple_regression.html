<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Regression_2_Multiple_Regression</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
<a href="https://github.com/weituo12321">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub" />
</a>
        <header id="banner" class="body">
                <h1><a href="/">HardCoreAI </a></h1>
                <nav><ul>
                    <li><a href="/category/announcement.html">Announcement</a></li>
                    <li class="active"><a href="/category/machine_learning.html">Machine_Learning</a></li>
                    <li><a href="/category/trial.html">trial</a></li>
                </ul>
                </nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/regression_2_multiple_regression.html" rel="bookmark"
           title="Permalink to Regression_2_Multiple_Regression">Regression_2_Multiple_Regression</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <span>Sat 02 April 2016</span>
<span>| tags: <a href="/tag/regression.html">regression</a></span>
</footer><!-- /.post-info -->      <h1>Multiple Regression</h1>
<p>For a simplicity, we start from a simple regression. We generate a polynomial model.  </p>
<div class="math">$$y_i = w_0+w_1x_i+w_2x_i^2+...+w_px_i^p+\epsilon_i$$</div>
<p>If we treat each order of x_i as a feature, then we may say it is a multiple regression with \(p+1\) features. Let's see a motivation application: detrending time series(My dear reader, i used to be good at signal processing, so do not fool around with me on that..). An example will be:  </p>
<div class="math">$$y_i=w_0+w_1t_i+w_2sin(\frac{2\pi t_i}{12} -\phi)+\epsilon_i$$</div>
<p>It is a periodic signal. Why is it? Because in summer good houses go quickly but in winter people prefer to stay inside house and not go outside to talk or make a deal. \(w_0t_i\) is the linear trend, the \(sin()\) is the seasonal component, a sinusoid with period 12 and the \( \phi \) is the unknown phase.(My dear reader, if you are not familiar with the concept, you can just forget it~ I will try to release the basic signal processing blogs later.) All right, let's do some high school math here.Since we have  </p>
<div class="math">$$sin(a-b)=sin(a)cos(b)-cos(a)sin(b)$$</div>
<p>So convert the seasonal component into:  </p>
<div class="math">$$sin(\frac{2\pi t_i}{12} -\phi)=sin(\frac{2\pi t_i}{12})cos(\phi)-cos(\frac{2\pi t_i}{12})sin(\phi)$$</div>
<p>Then we obtain  </p>
<div class="math">$$y_i=w_0+w_it_i+w_2sin(\frac{2\pi t_i}{12})+w_3cos(\frac{2\pi t_i}{12})+\epsilon_i$$</div>
<p>You can see that feature_1 is constant 1. Then feature_2 is t, feature_3 is \( sin(\frac{2\pi t_i}{12})\) and feature_4 is \( cos(\frac{2\pi t_i}{12})\). So sometimes it is a good reason to do the data visualization and data preprocessing! In this way we can choose the best model to represent the data. There are so many situations in which we should consider the seasonality. For example, in the weather modeling, the temperature, rainfall, cloud radiation and so many other factors are periodic. Other examples are flu monitoring, costume demand forcasting(like winter and summer), motion capture data, ECG/EEG, etc.  </p>
<h1>Generic Basis Expansion</h1>
<p>Instead of specific function, we can use function sign to represent the feature. So we have:  </p>
<div class="math">$$y_i=w_0h_0(x_i)+w_1h_1(x_i)+w_2h_2(x_i)+...+w_Dh_D(x_i)+\epsilon_i$$</div>
<p>Each \(h(x_i)\) represents a kind of function of \(x_i\). But it still only contains one attributes. Next we add more attributes. For example, in mind reading, features are brain region intensities. It is easy to do so. Just replace the single attributes with vector. That will be:  </p>
<div class="math">$$y_i=w_0h_0(\vec{x_i})+w_1h_1(\vec{x_i})+w_2h_2(\vec{x_i})+...+w_Dh_D(\vec{x_i})+\epsilon_i$$</div>
<p>Note that a function of a vector can be any kind of format. We can see clearly the difference of attributes and features. If we want to interpret the coefficients, we need to fix other features. We write the above function in a more generic notation.  </p>
<div class="math">$$y_i=\sum_{j=0}^{D}w_jh_j(\vec{x_i})+\epsilon_i$$</div>
<p>Note that it is a equation for one single data. Suppose we have \(N\) data points. There should be \(N\) equations. Now it is where linear algebra come for use. We continue to write it into matrix format.  </p>
<div class="math">$$\vec{y}=H \bullet W + \vec{\epsilon}$$</div>
<p>where \( \vec{y}\) is a column vector that contains all the \(N \) data target. \(H\) is a N-by-D dimension matrix(N data, each data has D features). \(W \) is the column vector of coefficients with length D. \( \vec{\epsilon} \) is a column vector with length N.(My dear reader, i strongly you write the matrix down to paper and check what exactly each row, each colum represents, who are scalars, who are vectors etc.) Next we will rewrite the RSS function in matrix format.  </p>
<div class="math">$$RSS(\vec{w})=(\vec{y}-H\vec{w})^{T}\bullet(\vec{y}-H\vec{w})$$</div>
<p>We know<br />
</p>
<div class="math">$$\vec{y}-H\vec{w}=\left[ \begin{array}{c} Residual_1 \\ Residual_2 \\ ... \\ Residual_N \end{array} \right]$$</div>
<p>Guess what? Using above equation, we know  </p>
<div class="math">$$RSS(\vec{w})=\sum_{i=1}^{N}Residual_i^2$$</div>
<p>Remember this equation since it will be useful when we implement the algorithms.  </p>
<h1>Get Maximum/Minimum</h1>
<p>Still we have two approaches here. The first one is to set gradient \( = 0\).  </p>
<div class="math">$$\triangledown RSS(\vec{w})=\triangledown \left[ (\vec{y}-H\vec{w})^{T}(\vec{y}-H\vec{w})\right]=-2H^{T}(\vec{y}-H\vec{w})$$</div>
<p>Sorry I give the result directly, should spend some time on how to conduct this result. Anyway, let's look at the first approach.   </p>
<div class="math">$$\triangledown RSS(\vec{w})=0 \Rightarrow -2H^{T}(\vec{y}-H\vec{w})=0$$</div>
<p>So we have  </p>
<div class="math">$$H^{T}\vec{y}=H^{T}H\vec{w}$$</div>
<p>Two sides of the above equation left muliply \((H^{T}H)^{-1} \) and we obtain  </p>
<div class="math">$$\hat{w}=(H^{T}H)^{-1}H^{T}\vec{y}$$</div>
<p>We can see the deficits of closed-form solution.The \(H^{T}H \) is a D-by-D matrix. It is invertible only if it has full rank.(There are no redundant rows or columns.) In most cases, the number of observation of data \( N \) is much larger than the feature dimensions \( D\). And the complexity of inverse is usually \( O(D^{3}) \). That's why we prefer our second approach.  </p>
<p>The second approach is gradient descent. Like the simple regression, we have:<br />
while not converged:<br />
</p>
<div class="math">$$\vec{w} \leftarrow \vec{w}^{(t)}-\eta(-2H^{T}(\vec{y}-H\vec{w}^{(t)}))$$</div>
<p>In practical, we update the coefficient feature by feature. Let's start from the residual sum of square function. Remember the following equation? </p>
<div class="math">$$RSS(\vec{w})=\sum_{i=1}^{N}[y_i-h(\vec{x_i})^{T}\vec{w}]^2$$</div>
<p>We take the partial derivative with respect to \(w_j\) and get:  </p>
<div class="math">$$\frac{\partial{RSS(\vec{w})}}{\partial{w_j}}=\sum_{i=1}^{N}2[y_i-h_0(x_i)w_0 - h_1(x_i)w_1-...-h_j(x_i)w_j-...h_D(x_i)w_D](-h_j(x_i))$$</div>
<div class="math">$$=-2\sum_{i=1}^{N}h_j(x_i)[y_i-h(x_i)^{T}\vec{w}]$$</div>
<p>So we can update \(j_{th}\) feature like this:  </p>
<div class="math">$$w_j^{(t+1)} \leftarrow w_j^{(t)}+2\eta\sum_{i=1}^{N}h_j(\vec{x_i})(y_i-\hat{y_i}(w^{(t)}))$$</div>
<p>In particular, \( \hat{y_i}(w^{(t)})\) means the predicted \( y_i\) calculated by \( w^{(t)}\).  </p>
<p>So if we turn it into pseudo-code we can summaize the gradient descent algorithm as follows:  </p>
<hr />
<p>init \( \vec{w}^{(1)}=0 \) (or randomly or smartly), \( t=1\) means the first iteration<br />
while \( ||\triangledown(RSS(w^{(t)}))|| &gt; \epsilon\):<br />
for j=0,...D:<br />
&ensp;&ensp;&ensp;&ensp;partial\([j]=-2\sum_{i=1}^{N}h_j(\vec{x_i})(y_i-\hat{y_i}(w^{(t)}))\)  </p>
<p>&ensp;&ensp;&ensp;&ensp;\(w_j^{(t+1)} \leftarrow w_j^{(t)}-\eta\)partial\([j]\)  </p>
<p>\(t \leftarrow t+1\)  </p>
<hr />
<p>Now we have a generic model and corresponding algorithm to solve this model. But how do we know which specific model is good? how to assess these models? To be continue... </p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://twitter.com/VicWeituo">twitter</a></li>
                            <li><a href="https://github.com/weituo12321">github</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <p>Powered by <a href="http://getpelican.com/">Pelican</a>. Theme <a href="https://github.com/blueicefield/pelican-blueidea/">blueidea</a>, inspired by the default theme.</p>
        </footer><!-- /#contentinfo -->

</body>
</html>